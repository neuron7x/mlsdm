name: Production Gate

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to release (e.g., 1.2.0)'
        required: true
        type: string
      skip_approval:
        description: 'Skip manual approval (for automation)'
        required: false
        type: boolean
        default: false
  release:
    types: [created]

permissions:
  contents: read
  packages: read

jobs:
  # Pre-flight checks - all must pass before approval
  preflight:
    name: Pre-flight Checks
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 with uv
        uses: astral-sh/uv-action@v3
        with:
          python-version: '3.11'
          enable-cache: true

      - name: Sync dependencies from lockfile
        run: uv sync --all-extras --frozen

      - name: Lint check
        run: uv run ruff check src tests

      - name: Type check
        run: uv run mypy src/mlsdm

      - name: Security vulnerability scan
        run: uv run pip-audit --strict --progress-spinner=off

      - name: Run all unit tests
        run: uv run pytest tests/unit -v --tb=short

      - name: Run integration tests
        run: uv run pytest tests/integration -v --tb=short -m "not slow"

      - name: Run E2E tests
        run: uv run pytest tests/e2e -v --tb=short -m "not slow"
        env:
          LLM_BACKEND: local_stub
          DISABLE_RATE_LIMIT: "1"

  # Run property-based tests
  property-tests:
    name: Property-Based Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 with uv
        uses: astral-sh/uv-action@v3
        with:
          python-version: '3.11'
          enable-cache: true

      - name: Sync dependencies from lockfile
        run: uv sync --all-extras --frozen

      - name: Run property tests
        run: uv run pytest tests/property -v --tb=short --maxfail=10
        timeout-minutes: 20

  # Run SLO validation
  slo-validation:
    name: SLO Validation
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 with uv
        uses: astral-sh/uv-action@v3
        with:
          python-version: '3.11'
          enable-cache: true

      - name: Sync dependencies from lockfile
        run: uv sync --all-extras --frozen

      - name: Run effectiveness suite with SLO validation
        run: uv run python scripts/run_effectiveness_suite.py --validate-slo

      - name: Run performance benchmarks
        run: uv run pytest benchmarks/test_neuro_engine_performance.py -v -s --tb=short

      - name: Upload SLO report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: slo-validation-report
          path: |
            reports/effectiveness_snapshot.json
            reports/EFFECTIVENESS_SNAPSHOT.md
          retention-days: 90

  # SAST security scan
  security-scan:
    name: Security Analysis
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.11 with uv
        uses: astral-sh/uv-action@v3
        with:
          python-version: '3.11'
          enable-cache: true

      - name: Sync dependencies from lockfile
        run: uv sync --all-extras --frozen

      - name: Run bandit (high severity check)
        run: |
          # Fail if any high severity issues found
          uv run bandit -r src/mlsdm \
            --severity-level high \
            --confidence-level high \
            -f txt

      - name: Dependency audit
        run: uv run pip-audit --strict

  # Validate documentation
  docs-validation:
    name: Documentation Validation
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check required docs exist
        run: |
          docs=(
            "README.md"
            "CHANGELOG.md"
            "SECURITY_POLICY.md"
            "DEPLOYMENT_GUIDE.md"
            "RUNBOOK.md"
            "API_REFERENCE.md"
          )

          for doc in "${docs[@]}"; do
            if [ ! -f "$doc" ]; then
              echo "ERROR: Required documentation $doc not found"
              exit 1
            fi
            echo "✓ $doc exists"
          done

      - name: Check changelog has version entry
        env:
          VERSION: ${{ github.event.inputs.version || github.ref_name }}
        run: |
          if grep -q "## \[${VERSION}\]" CHANGELOG.md 2>/dev/null || grep -q "## ${VERSION}" CHANGELOG.md 2>/dev/null; then
            echo "✓ CHANGELOG.md has entry for version $VERSION"
          else
            echo "WARNING: CHANGELOG.md may not have entry for version $VERSION"
          fi

  # Manual approval gate
  approval:
    name: Manual Approval
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: [preflight, property-tests, slo-validation, security-scan, docs-validation]
    if: ${{ github.event.inputs.skip_approval != 'true' }}
    environment: production

    steps:
      - name: Approval received
        env:
          VERSION: ${{ github.event.inputs.version || github.ref_name }}
        run: |
          echo "✓ Production deployment approved"
          echo "Version: $VERSION"
          echo "Approved at: $(date -u)"

  # Final gate check
  gate-passed:
    name: Production Gate Passed
    runs-on: ubuntu-latest
    timeout-minutes: 5
    needs: [preflight, property-tests, slo-validation, security-scan, docs-validation, approval]
    if: always()

    steps:
      - name: Check all jobs passed
        run: |
          if [ "${{ needs.preflight.result }}" != "success" ]; then
            echo "ERROR: Pre-flight checks failed"
            exit 1
          fi
          if [ "${{ needs.property-tests.result }}" != "success" ]; then
            echo "ERROR: Property tests failed"
            exit 1
          fi
          if [ "${{ needs.slo-validation.result }}" != "success" ]; then
            echo "ERROR: SLO validation failed"
            exit 1
          fi
          if [ "${{ needs.security-scan.result }}" != "success" ]; then
            echo "ERROR: Security scan failed"
            exit 1
          fi
          if [ "${{ needs.docs-validation.result }}" != "success" ]; then
            echo "ERROR: Documentation validation failed"
            exit 1
          fi
          # Check approval if it was required (not skipped)
          if [ "${{ needs.approval.result }}" = "failure" ]; then
            echo "ERROR: Manual approval not received"
            exit 1
          fi

          echo "✓ All production gate checks passed"
          echo "Ready for production deployment"
