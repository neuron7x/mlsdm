"""Memory Provenance System for AI Safety.

This module provides metadata tracking for memory sources and confidence levels
to prevent hallucination propagation in the Phase-Entangled Lattice Memory (PELM).

Key Components:
- MemorySource: Enum defining the origin of a memory (user input, LLM generation, etc.)
- MemoryProvenance: Dataclass tracking source, confidence, timestamp, and lineage

AI Safety Goals:
- Track memory origin to distinguish human input from LLM-generated content
- Assign confidence scores to filter low-quality or potentially hallucinated memories
- Enable confidence-based eviction and retrieval strategies
- Maintain audit trail of memory lineage

Resolves: TD-003 (HIGH priority - AI Safety critical)
"""

from __future__ import annotations

from dataclasses import dataclass
from enum import Enum
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from datetime import datetime


class MemorySource(Enum):
    """Source of memory origin for provenance tracking.

    Attributes:
        USER_INPUT: Direct input from user (highest confidence default)
        LLM_GENERATION: Content generated by LLM (potential hallucination risk)
        RETRIEVED_CONTEXT: Retrieved from existing memory
        SYSTEM_PROMPT: System-level prompts or configuration
    """

    USER_INPUT = "user_input"
    LLM_GENERATION = "llm_generation"
    RETRIEVED_CONTEXT = "retrieved"
    SYSTEM_PROMPT = "system"


@dataclass
class MemoryProvenance:
    """Metadata tracking the origin and reliability of a memory.

    Attributes:
        source: The origin of this memory (user, LLM, system, etc.)
        confidence: Reliability score in [0.0, 1.0], where 1.0 = highest confidence
        timestamp: When this memory was created
        llm_model: Name of the LLM model if source is LLM_GENERATION
        parent_id: Optional ID of parent memory (for lineage tracking)

    Raises:
        ValueError: If confidence is not in [0.0, 1.0] range

    Example:
        >>> from datetime import datetime
        >>> prov = MemoryProvenance(
        ...     source=MemorySource.USER_INPUT,
        ...     confidence=0.95,
        ...     timestamp=datetime.now()
        ... )
        >>> prov.is_high_confidence
        True
    """

    source: MemorySource
    confidence: float
    timestamp: datetime
    llm_model: str | None = None
    parent_id: str | None = None

    def __post_init__(self) -> None:
        """Validate confidence is in valid range [0.0, 1.0]."""
        if not 0.0 <= self.confidence <= 1.0:
            raise ValueError(
                f"Confidence must be in range [0.0, 1.0], got {self.confidence}. "
                "Use 1.0 for highest confidence, 0.0 for lowest."
            )

    @property
    def is_high_confidence(self) -> bool:
        """Check if memory has high confidence (â‰¥0.7).

        Returns:
            True if confidence >= 0.7, False otherwise
        """
        return self.confidence >= 0.7

    @property
    def is_llm_generated(self) -> bool:
        """Check if memory was generated by an LLM (potential hallucination).

        Returns:
            True if source is LLM_GENERATION, False otherwise
        """
        return self.source == MemorySource.LLM_GENERATION
